---
title: "Project Model"
author: "Lynn Fan"
date: "4/26/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library(tidyverse)
library(dplyr)
library(glmnet)
library(car)
library(R2WinBUGS)
library(MASS)
library(data.table)
library(bayesm)
install.packages("R2admb")
install.packages("glmmADMB",
                  repos="http://glmmadmb.r-forge.r-project.org/repos",
                  type="source")
library(R2admb)
library(glmmADMB)
library(lme4)
library(tidyr)
```

## Data Cleanup
```{r data cleanup}
data <- read.table("rawdata.txt", 
               col.names=c('stops', 'pop', 'past.arrests', 'precinct', 'eth', 'crime'), 
               fill=FALSE, 
               strip.white=TRUE)
```


## Exploratory Data Analysis
```{r dispersion}
r <- c(mean(data$stops), var(data$stops))
c(mean=r[1], var=r[2], ratio=r[2]/r[1])
```
Overdispersed, so we should do Negative Binomial instead of Poisson.

```{r regression}
stops<-data$stops ; ethi<-as.factor(data$eth) ; precinct<-as.factor(data$precinct);arrest=data$past.arrests
overdisp_fun <- function(model) {
    rdf <- df.residual(model)
    rp <- residuals(model,type="pearson")
    Pearson.chisq <- sum(rp^2)
    prat <- Pearson.chisq/rdf
    pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
# Poisson with random effects
fit.poi <- glmer(stops~1+ethi+(1|precinct),family = poisson(link = "log"), nAGQ = 100)
summary(fit.poi)
overdisp_fun(fit.poi)
# Negative Binomial
fit.nb <- glmer.nb(stops~1+ethi+(1|precinct), verbose=TRUE)
summary(fit.nb)
overdisp_fun(fit.nb)
```

```{r hierarchial}
n <- nrow(data)
precinct.number <- unique(data$precinct)
n.precinct <- length(precinct.number)
precincts <- rep(NA,n)
pblack <- rep(NA,n.precinct)
for (i in 1:n.precinct) {
  precincts[data$precinct==precinct.number[i]] <- i
  temp <- data[data$precinct==i,]
  blackpop <- temp[temp$eth==1,]$pop[1]
  totalpop <- temp[temp$eth==1,]$pop[1]+temp[temp$eth==2,]$pop[1]+temp[temp$eth==3,]$pop[1]
  pblack[i]<-blackpop/totalpop
}
precinct.category <- ifelse (pblack < .1, 1, ifelse (pblack < .4, 2, 3))
dcjs <- log(arrests*15/12)
dcjs[which(!is.finite(dcjs))] <- 0
crime <- data$crime
pop <- data$pop
stop_df <- as.data.frame (cbind (stops, ethi, precincts, crime, precinct.category, arrests, dcjs, pop))
# Multilevel analysis of NYC police stops

# lmer() fits
M1 <- as.list (rep (NA, 12))
M2 <- as.list (rep (NA, 12))
index <- 0
for (j in 1:3){
  for (k in 1:4){
    index <- index + 1
    ok <- precinct.category==j & crime==k
    M1[[index]] <- glmer(stops ~ dcjs + ethi + (1|precincts),
     family=poisson(link="log"), subset=ok, data=stop_df)
    M2[[index]] <- glmer.nb(stops~dcjs+ethi+(1|precincts), verbose=TRUE, subset=ok,data=stop_df)
  }
}
M1[1]
M2[1]
anova(M1[[1]],M2[[1]])
```
negative binomial with overdispersion effect

```{r mcmc}
## Metropolis sampling
## x    - current value of Markov chain (numeric vector)
## targ - target log density function
## prop - function with prototype function(x, ...) that generates 
##   a proposal value from a symmetric proposal distribution
library('mvtnorm')
prop_mvnorm <- function(x, ...)
  drop(rmvnorm(1, mean=x, ...))
metropolis <- function(x, targ, prop=prop_mvnorm, ...) {
  xnew <- prop(x)
  lrat <- targ(xnew, ...) - targ(x, ...)
  if(log(runif(1)) < lrat)
    x <- xnew
  return(x)
}

## Metropolis-in-Gibbs sampling
## x    - current value of Markov chain (numeric vector)
## targ - target log density function
## ...  - arguments passed to 'targ'
gibbs <- function(x, targ, ...) {
  for(i in 1:length(x)) {
    ## define full conditional
    targ1 <- function(x1, ...) {
      x[i] <- x1
      targ(x, ...)
    }
    ## sample using Metropolis algorithm
    x[i] <- metropolis(x[i], targ1, ...)
  }
  return(x)
}
```
how do we know proposal distribution? MVN
Poisson GLM with random effects
If NB: link function for negative binomial, try a bayesian glm package, see the parametization, and change the link
  for negative binomial, the r parameter:
  you need to sample both from beta and r for posterior sampling
  
prior for beta: MVN or whatever in the package
prior for r: uninformative uniform distribution

```{r mh-songbird}
# Useful variables
y<-stops ; X<-cbind(rep(1,length(y)),ethi)
yX<-cbind(y,X)
colnames(yX)<-c("fledged","intercept","ethi") 

n<-length(y) ; p<-dim(X)[2]

# Prior parameters
pmn.beta<-rep(0,p) # prior mean for beta
psd.beta<-rep(10,p) # prior sd for beta

# Metropolis settings
var.prop<- var(log(y+1/2))*solve( t(X)%*%X ) #variance for proposal distribution
beta<-rep(0,p) #initial beta
S<-10000 # no. of MCMC samples
BETA<-matrix(0,nrow=S,ncol=p) #container
ac<-0 # no. of accepts in MCMc
set.seed(1)

## rmvnorm function for proposals
rmvnorm<-function(n,mu,Sigma)
{ # samples from the multivariate normal distribution
  E<-matrix(rnorm(n*length(mu)),n,length(mu))
  t(  t(E%*%chol(Sigma)) +c(mu))
}

## MCMC
for(s in 1:S) {
  
  #proposal: sample a candidate beta
  beta.p<- t(rmvnorm(1, beta, var.prop ))
  
  #evaluate: compute log-acceptance-ratio, then accept/reject
  lhr<- sum(dpois(y,exp(X%*%beta.p),log=T)) -
    sum(dpois(y,exp(X%*%beta),log=T)) +
    sum(dnorm(beta.p,pmn.beta,psd.beta,log=T)) -
    sum(dnorm(beta,pmn.beta,psd.beta,log=T))
  
  if( log(runif(1))< lhr ) { beta<-beta.p ; ac<-ac+1 }
  
  BETA[s,]<-beta #store sample
}
cat(ac/S,"\n") #acceptance rate of MCMC

library(coda)
apply(BETA,2,effectiveSize) #ESS



#### Figure 10.5 (traceplots & ACF)
par(mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
par(mfrow=c(1,3))
blabs<-c(expression(beta[1]),expression(beta[2]))
thin<-c(1,(1:1000)*(S/1000))
j<-2
plot(thin,BETA[thin,j],type="l",xlab="iteration",ylab=blabs[j])
abline(h=mean(BETA[,j]) )

acf(BETA[,j],ci.col="gray",xlab="lag")
acf(BETA[thin,j],xlab="lag/10",ci.col="gray") #ACF of thinned chain 


#### Figure 10.6
par(mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
par(mfrow=c(1,3))

# Computing "true" density via grid approximation
p<-3
beta0<-rep(0,p)
S0<-diag( rep(100,3))
gs<-100
LPB<-array(0,dim=rep(gs,p))

beta1<-seq(.27-1.75,.27+1.75,length=gs)
beta2<-seq(.68-1.5,.68+1.5,length=gs)

beta1<-seq(.27-2.5,.27+2.5,length=gs)
beta2<-seq(.68-2,.68+2,length=gs)

for(i in 1:gs) { for(j in 1:gs) { for(k in 1:gs) {
  theta<-beta1[i]+beta2[j]*data$eth+beta3[k]*data$precinct
  LPB[i,j,k]<-dnorm(beta1[i],beta0[1],sqrt(S0[1,1]),log=TRUE)  +
    dnorm(beta2[j],beta0[2],sqrt(S0[2,2]),log=TRUE)  
    sum( dpois(stops,exp(theta),log=TRUE )  )
}} }

PB<-exp( LPB - max(LPB) )
PB<-PB/sum(PB)

PB1<-apply(PB,1,sum)
PB2<-apply(PB,2,sum)
PB3<-apply(PB,3,sum)
PB23<-apply(PB,c(2,3),sum)

# Plot true posterior marginals with MCMC estimated marginals
plot(beta2,PB2*length(beta2)/(max(beta2)-min(beta2)) ,type="l",xlab=expression(beta[2]),ylab=expression(paste(italic("p("),beta[2],"|",italic("y)"),sep="") ) ,lwd=2,lty=2,col="gray")
lines(density(BETA[,2],adj=2),lwd=2)

plot(beta3,PB3*length(beta3)/(max(beta3)-min(beta3)),type="l",xlab=expression(beta[3]),ylab=expression(paste(italic("p("),beta[3],"|",italic("y)"),sep="") ),lwd=2,col="gray",lty=2)
lines(density(BETA[,3],adj=2),lwd=2)

# Plot posterior quantiles of predicted count rate of Poisson reg model
Xs<-cbind(rep(1,6),1:6,(1:6)^2) 
eXB.post<- exp(t(Xs%*%t(BETA )) )
qE<-apply( eXB.post,2,quantile,probs=c(.025,.5,.975))

plot( c(1,6),range(c(0,qE)),type="n",xlab="age",
      ylab="number of offspring")
lines( qE[1,],col="black",lwd=1)
lines( qE[2,],col="black",lwd=2)
lines( qE[3,],col="black",lwd=1)

```  
### References:
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#fitting-models-with-overdispersion
https://sakai.duke.edu/access/content/group/cd23a148-0b53-4d1c-9d1e-c66c74e59129/Lectures/songbird.R
